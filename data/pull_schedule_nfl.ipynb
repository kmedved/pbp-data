{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import http\n",
    "from urllib.error import URLError, HTTPError, ContentTooShortError\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def download(url, num_retries=5): \n",
    "#     print('Downloading:', url)\n",
    "    try: \n",
    "        time.sleep(1)\n",
    "        html = urllib.request.urlopen(url).read()\n",
    "    except (URLError, HTTPError, ContentTooShortError, http.client.HTTPException) as e: \n",
    "        print('Download error:', e.reason,url)\n",
    "        html = None \n",
    "        if num_retries > 0: \n",
    "            if hasattr(e, 'code') and 500 <= e.code < 600: \n",
    "                time.sleep(10)\n",
    "                # recursively retry 5xx HTTP errors \n",
    "                return download(url, num_retries - 1) \n",
    "    return html\n",
    "\n",
    "\n",
    "def nfl_calendar(season):\n",
    "    url = \"http://site.api.espn.com/apis/site/v2/sports/football/nfl/scoreboard?dates={}\".format(season)\n",
    "    resp = urllib.request.urlopen(url)\n",
    "    txt = json.loads(resp.read())['leagues'][0]['calendar']\n",
    "    full_schedule = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    for val in range(0,len(txt)):\n",
    "        if 'entries' in txt[val].keys():\n",
    "            pre = pd.json_normalize(\n",
    "                data = txt[val],\n",
    "                record_path = 'entries',\n",
    "                meta = ['label', 'value', 'startDate','endDate'],\n",
    "                meta_prefix = 'seasontype.',\n",
    "                errors = 'ignore'\n",
    "            )\n",
    "            full_schedule = pd.concat([full_schedule, pre], ignore_index=True)\n",
    "        else:\n",
    "            full_schedule = pd.concat([full_schedule, pd.json_normalize(txt[val])], ignore_index=True)\n",
    "    full_schedule['year'] = season\n",
    "    full_schedule['daysForward'] = (pd.to_datetime(full_schedule['endDate'])-pd.to_datetime(full_schedule['startDate'])).dt.days+1\n",
    "    date = pd.to_datetime(pd.to_datetime(full_schedule['startDate']).dt.date,format='%Y-%m-%d')\n",
    "    full_schedule['str_startDate']=date.apply(lambda x: x.strftime('%Y%m%d'))\n",
    "    full_schedule['url']=\"http://site.api.espn.com/apis/site/v2/sports/football/nfl/scoreboard?groups=20&limit=1000&dates=\"\n",
    "    full_schedule['url'] = full_schedule[['url','str_startDate']].apply(lambda x: \n",
    "                        ''.join(x),axis=1)\n",
    "    full_schedule['daysForward'] = full_schedule['daysForward'].apply(str)\n",
    "    full_schedule['url'] = full_schedule[['url','daysForward']].apply(lambda x: \n",
    "                        '&daysForward='.join(x),axis=1)\n",
    "    full_schedule = full_schedule[['year','value','str_startDate','daysForward','url']+\n",
    "                                  [col for col in full_schedule.columns \n",
    "                                   if col not in ['year','value','str_startDate','daysForward','url']]]\n",
    "    \n",
    "    full_schedule['group'] = 20\n",
    "    \n",
    "    return full_schedule\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "calendar_table = pd.DataFrame()\n",
    "calendar = {}\n",
    "for x in range(2001,2022):\n",
    "    year_calendar = nfl_calendar(x)\n",
    "    calendar_table = calendar_table.append(year_calendar)\n",
    "    year_calendar.to_json(orient='records')\n",
    "    calendar[x]=year_calendar\n",
    "    \n",
    "data_dict = {\n",
    "    key: calendar[key].to_dict(orient='records')\n",
    "    for key in calendar.keys()\n",
    "}\n",
    "\n",
    "with open('nfl_calendar.json','w') as fp:\n",
    "    json.dump(\n",
    "    data_dict,\n",
    "    fp,\n",
    "    indent=4,\n",
    "    sort_keys=True)    \n",
    "calendar_table.to_csv('nfl_calendar_2002_2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 2020\n",
      "pre\n",
      "reg\n",
      "post\n"
     ]
    }
   ],
   "source": [
    "def nfl_schedule(year):\n",
    "    ev = pd.DataFrame()\n",
    "    print(f\"Working on {year}\")\n",
    "    season_types = ['pre','reg','post']\n",
    "    for i in season_types:\n",
    "        url = \"http://site.api.espn.com/apis/site/v2/sports/football/nfl/scoreboard?seasontype={}&limit=1000&dates={}\".format(i, year)\n",
    "        resp = download(url=url)\n",
    "        events_txt = json.loads(resp)\n",
    "        events = events_txt['events']\n",
    "        for event in events:\n",
    "            bad_keys = ['linescores', 'statistics', 'leaders',  'records']\n",
    "            for k in bad_keys:\n",
    "                if k in event['competitions'][0]['competitors'][0].keys():\n",
    "                    del event['competitions'][0]['competitors'][0][k]\n",
    "                if k in event['competitions'][0]['competitors'][1].keys():\n",
    "                    del event['competitions'][0]['competitors'][1][k]\n",
    "            if 'links' in event['competitions'][0]['competitors'][0]['team'].keys():\n",
    "                del event['competitions'][0]['competitors'][0]['team']['links']\n",
    "            if 'links' in event['competitions'][0]['competitors'][1]['team'].keys():\n",
    "                del event['competitions'][0]['competitors'][1]['team']['links']    \n",
    "            if event['competitions'][0]['competitors'][0]['homeAway']=='home':\n",
    "                event['competitions'][0]['home'] = event['competitions'][0]['competitors'][0]['team']    \n",
    "            else: \n",
    "                event['competitions'][0]['away'] = event['competitions'][0]['competitors'][0]['team']\n",
    "            if event['competitions'][0]['competitors'][1]['homeAway']=='away':\n",
    "                event['competitions'][0]['away'] = event['competitions'][0]['competitors'][1]['team']\n",
    "            else: \n",
    "                event['competitions'][0]['home'] = event['competitions'][0]['competitors'][1]['team']\n",
    "\n",
    "            del_keys = ['notes','leaders','competitors', 'broadcasts','geoBroadcasts', 'headlines']\n",
    "            for k in del_keys:\n",
    "                if k in event['competitions'][0].keys():\n",
    "                    del event['competitions'][0][k]\n",
    "                    \n",
    "            ev = ev.append(pd.json_normalize(event['competitions'][0]))\n",
    "    ev['season']=year\n",
    "\n",
    "    return ev.drop_duplicates()\n",
    "\n",
    "f = nfl_schedule(2020)\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 2001\n",
      "pre\n",
      "reg\n",
      "post\n",
      "Working on 2002\n",
      "pre\n",
      "reg\n",
      "post\n",
      "Working on 2003\n",
      "pre\n",
      "Download error: Bad Gateway http://site.api.espn.com/apis/site/v2/sports/football/nfl/scoreboard?seasontype=pre&limit=1000&dates=2003\n",
      "Download error: Bad Gateway http://site.api.espn.com/apis/site/v2/sports/football/nfl/scoreboard?seasontype=pre&limit=1000&dates=2003\n",
      "Download error: Bad Gateway http://site.api.espn.com/apis/site/v2/sports/football/nfl/scoreboard?seasontype=pre&limit=1000&dates=2003\n",
      "reg\n",
      "post\n",
      "Working on 2004\n",
      "pre\n",
      "reg\n",
      "post\n",
      "Working on 2005\n",
      "pre\n",
      "reg\n",
      "post\n",
      "Working on 2006\n",
      "pre\n",
      "reg\n",
      "post\n",
      "Working on 2007\n",
      "pre\n",
      "reg\n",
      "post\n",
      "Working on 2008\n",
      "pre\n",
      "reg\n",
      "post\n",
      "Working on 2009\n",
      "pre\n",
      "reg\n",
      "post\n",
      "Working on 2010\n",
      "pre\n",
      "reg\n",
      "post\n",
      "Working on 2011\n",
      "pre\n",
      "reg\n",
      "post\n",
      "Working on 2012\n",
      "pre\n",
      "reg\n",
      "post\n",
      "Working on 2013\n",
      "pre\n",
      "reg\n",
      "post\n",
      "Working on 2014\n",
      "pre\n",
      "reg\n",
      "post\n",
      "Working on 2015\n",
      "pre\n",
      "reg\n",
      "post\n",
      "Working on 2016\n",
      "pre\n",
      "reg\n",
      "post\n",
      "Working on 2017\n",
      "pre\n",
      "reg\n",
      "post\n",
      "Working on 2018\n",
      "pre\n",
      "reg\n",
      "post\n",
      "Working on 2019\n",
      "pre\n",
      "reg\n",
      "post\n",
      "Working on 2020\n",
      "pre\n",
      "reg\n",
      "post\n",
      "Working on 2021\n",
      "pre\n",
      "reg\n",
      "post\n"
     ]
    }
   ],
   "source": [
    "schedule_table = pd.DataFrame()\n",
    "schedule = {}\n",
    "for x in range(2001,2022):\n",
    "    year_schedule = nfl_schedule(x)\n",
    "    year_schedule.to_csv(f\"nfl/schedules/nfl_games_info_{x}.csv\")\n",
    "    schedule_table = schedule_table.append(year_schedule)\n",
    "    schedule[x]=year_schedule\n",
    "\n",
    "\n",
    "schedule_table.to_csv('nfl_games_info_2002_2021.csv')\n",
    "    \n",
    "# event['competitions'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
