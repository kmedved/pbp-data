{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import http\n",
    "from urllib.error import URLError, HTTPError, ContentTooShortError\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def download(url, num_retries=5): \n",
    "#     print('Downloading:', url)\n",
    "    try: \n",
    "        time.sleep(1)\n",
    "        html = urllib.request.urlopen(url).read()\n",
    "    except (URLError, HTTPError, ContentTooShortError, http.client.HTTPException) as e: \n",
    "        print('Download error:', e.reason,url)\n",
    "        html = None \n",
    "        if num_retries > 0: \n",
    "            if hasattr(e, 'code') and 500 <= e.code < 600: \n",
    "                time.sleep(10)\n",
    "                # recursively retry 5xx HTTP errors \n",
    "                return download(url, num_retries - 1) \n",
    "    return html\n",
    "\n",
    "def cbb_calendar(season):\n",
    "    url = \"http://site.api.espn.com/apis/site/v2/sports/basketball/mens-college-basketball/scoreboard?dates={}\".format(season)\n",
    "    resp = download(url=url)\n",
    "    txt = json.loads(resp)['leagues'][0]['calendar']\n",
    "    datenum = list(map(lambda x: x[:10].replace(\"-\",\"\"),txt))\n",
    "    date = list(map(lambda x: x[:10],txt))\n",
    "    \n",
    "    year = list(map(lambda x: x[:4],txt))\n",
    "    month = list(map(lambda x: x[5:7],txt))\n",
    "    day = list(map(lambda x: x[8:10],txt))\n",
    "    \n",
    "    data = {\"season\": season,\n",
    "            \"datetime\" : txt,\n",
    "            \"date\" : date,\n",
    "            \"year\": year,\n",
    "            \"month\": month,\n",
    "            \"day\": day,\n",
    "            \"dateURL\": datenum\n",
    "            \n",
    "           }\n",
    "    df = pd.DataFrame(data)\n",
    "    df['url']=\"http://site.api.espn.com/apis/site/v2/sports/football/college-football/scoreboard?dates=\"\n",
    "    df['url']= df['url'] + df['dateURL']\n",
    "    return df\n",
    "\n",
    "cbb_calendar(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth',None)\n",
    "schedule = {}\n",
    "for x in range(2001,2022):\n",
    "    full_schedule = cbb_calendar(x)\n",
    "    full_schedule.to_json(orient='records')\n",
    "    schedule[x]=full_schedule\n",
    "    \n",
    "data_dict = {\n",
    "    key: schedule[key].to_dict(orient='records')\n",
    "    for key in schedule.keys()\n",
    "}\n",
    "\n",
    "with open('cbb_schedule.json','w') as fp:\n",
    "    json.dump(\n",
    "    data_dict,\n",
    "    fp,\n",
    "    indent=4,\n",
    "    sort_keys=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import http\n",
    "from urllib.error import URLError, HTTPError, ContentTooShortError\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def download(url, num_retries=5): \n",
    "#     print('Downloading:', url)\n",
    "    try: \n",
    "        time.sleep(1)\n",
    "        html = urllib.request.urlopen(url).read()\n",
    "    except (URLError, HTTPError, ContentTooShortError, http.client.HTTPException) as e: \n",
    "        print('Download error:', e.reason,url)\n",
    "        html = None \n",
    "        if num_retries > 0: \n",
    "            if hasattr(e, 'code') and 500 <= e.code < 600: \n",
    "                time.sleep(10)\n",
    "                # recursively retry 5xx HTTP errors \n",
    "                return download(url, num_retries - 1) \n",
    "    return html\n",
    "\n",
    "def cbb_schedule(year):\n",
    "    url = \"http://site.api.espn.com/apis/site/v2/sports/basketball/mens-college-basketball/scoreboard?dates={}\".format(year)\n",
    "    resp = download(url=url)\n",
    "    txt = json.loads(resp)['leagues'][0]['calendar']\n",
    "#     print(len(txt))\n",
    "    txt = list(map(lambda x: x[:10].replace(\"-\",\"\"),txt))\n",
    "    \n",
    "    ev = pd.DataFrame()\n",
    "    i=0\n",
    "    for date in txt:\n",
    "        print(f\"Working on {year}: {i+1} of {len(txt)}, date: {txt[i]}\")\n",
    "        url = \"http://site.api.espn.com/apis/site/v2/sports/basketball/mens-college-basketball/scoreboard?groups=50&dates={}\".format(date)\n",
    "        resp = download(url=url)\n",
    "        events_txt = json.loads(resp)\n",
    "        events = events_txt['events']\n",
    "        for event in events:\n",
    "            bad_keys = ['linescores', 'statistics', 'leaders',  'records']\n",
    "            for k in bad_keys:\n",
    "                if k in event['competitions'][0]['competitors'][0].keys():\n",
    "                    del event['competitions'][0]['competitors'][0][k]\n",
    "                if k in event['competitions'][0]['competitors'][1].keys():\n",
    "                    del event['competitions'][0]['competitors'][1][k]\n",
    "            if 'links' in event['competitions'][0]['competitors'][0]['team'].keys():\n",
    "                del event['competitions'][0]['competitors'][0]['team']['links']\n",
    "            if 'links' in event['competitions'][0]['competitors'][1]['team'].keys():\n",
    "                del event['competitions'][0]['competitors'][1]['team']['links']    \n",
    "            if event['competitions'][0]['competitors'][0]['homeAway']=='home':\n",
    "                event['competitions'][0]['home'] = event['competitions'][0]['competitors'][0]['team']    \n",
    "            else: \n",
    "                event['competitions'][0]['away'] = event['competitions'][0]['competitors'][0]['team']\n",
    "            if event['competitions'][0]['competitors'][1]['homeAway']=='away':\n",
    "                event['competitions'][0]['away'] = event['competitions'][0]['competitors'][1]['team']\n",
    "            else: \n",
    "                event['competitions'][0]['home'] = event['competitions'][0]['competitors'][1]['team']\n",
    "\n",
    "            del_keys = ['competitors', 'broadcasts','geoBroadcasts', 'headlines']\n",
    "            for k in del_keys:\n",
    "                if k in event['competitions'][0].keys():\n",
    "                    del event['competitions'][0][k]\n",
    "\n",
    "            ev = ev.append(pd.json_normalize(event['competitions'][0]))\n",
    "        i+=1\n",
    "    ev['season']=year\n",
    "    return ev\n",
    "\n",
    "schedule_table = pd.DataFrame()\n",
    "schedule = {}\n",
    "for x in range(2002,2022):\n",
    "    year_schedule = cbb_schedule(x)\n",
    "    year_schedule.to_csv(f\"cbb_games_info_{x}.csv\")\n",
    "    schedule_table = schedule_table.append(year_schedule)\n",
    "    year_schedule.to_json(orient='records')\n",
    "    schedule[x]=year_schedule\n",
    "    \n",
    "data_dict = {\n",
    "    key: schedule[key].to_dict(orient='records')\n",
    "    for key in schedule.keys()\n",
    "}\n",
    "\n",
    "with open('cbb_schedule.json','w') as fp:\n",
    "    json.dump(\n",
    "    data_dict,\n",
    "    fp,\n",
    "    indent=4,\n",
    "    sort_keys=True)\n",
    "\n",
    "schedule_table.to_csv('cbb_games_info_2002_2021.csv')\n",
    "    \n",
    "# event['competitions'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
